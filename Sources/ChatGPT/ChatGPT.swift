//
//  Copyright © 2023 Dennis Müller and all collaborators
//
//  Permission is hereby granted, free of charge, to any person obtaining a copy
//  of this software and associated documentation files (the "Software"), to deal
//  in the Software without restriction, including without limitation the rights
//  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
//  copies of the Software, and to permit persons to whom the Software is
//  furnished to do so, subject to the following conditions:
//
//  The above copyright notice and this permission notice shall be included in all
//  copies or substantial portions of the Software.
//
//  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
//  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
//  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
//  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
//  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
//  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
//  SOFTWARE.
//

import Foundation
import Get
import Base
import GPTSwiftSharedTypes

/// A simple and easy to use wrapper around the ChatGPT API from OpenAI, with support for GPT 3.5 turbo as well as GPT 4 and its large context variant.
public class ChatGPT {

    private let client: APIClient
    private let apiClientRequestHandler: APIClientRequestHandler

    private let defaultModel: ChatGPTModel

    /// A variant of `ChatGPT` that streams all the answers.
    ///
    /// This exposes the exact same methods as before, but it returns an `AsyncThrowingStream` that yields individual tokens as soon as they are generated by GPT.
    public let streamedAnswer: StreamedAnswer

    /// A simple and easy to use wrapper around the ChatGPT API from OpenAI, with support for GPT 3.5 turbo as well as GPT 4 and its large context variant.
    ///
    /// - Parameter apiKey: The api key you can generate in your account page on OpenAI's website.
    /// - Parameter defaultModel: Sets the default model for all requests coming from this `ChatGPT` instance.
    public init(apiKey: String, defaultModel: ChatGPTModel = .gpt3) {
        self.apiClientRequestHandler = .init(apiKey: apiKey)
        self.defaultModel = defaultModel
        self.client = APIClient(baseURL: URL(string: API.base)) { [apiClientRequestHandler] configuration in
            configuration.delegate = apiClientRequestHandler
        }
        self.streamedAnswer = .init(client: client, apiKey: apiKey, defaultModel: defaultModel)
    }

    /// Ask ChatGPT a single prompt without any special configuration.
    /// - Parameter userPrompt: The prompt to send
    /// - Parameter systemPrompt: an optional system prompt to give GPT instructions on how to answer.
    /// - Parameter model: The model that should be used.
    /// - Returns: The response as string.
    public func ask(
        _ userPrompt: String,
        withSystemPrompt systemPrompt: String? = nil,
        model: ChatGPTModel = .default
    ) async throws -> String {
        var messages: [ChatMessage] = []

        if let systemPrompt {
            messages.insert(.init(role: .system, content: systemPrompt), at: 0)
        }

        messages.append(.init(role: .user, content: userPrompt))

        let usingModel = model is DefaultChatGPTModel ? defaultModel : model
        let request = Request<ChatResponse>(
            path: API.v1ChatCompletion,
            method: .post,
            body: ChatRequest(model: usingModel, messages: messages)
        )

        let response = try await send(request: request)
        guard let answer = response.choices.first?.message.content else {
            throw GPTSwiftError.other(CustomError.couldNotParseAnswer)
        }

        return answer
    }

    /// Ask ChatGPT something by sending multiple messages without any special configuration.
    /// - Parameter messages: The chat messages.
    /// - Parameter model: The model that should be used.
    /// - Returns: The response.
    public func ask(
        messages: [ChatMessage],
        model: ChatGPTModel = .default
    ) async throws -> String {
        let usingModel = model is DefaultChatGPTModel ? defaultModel : model
        let request = Request<ChatResponse>(
            path: API.v1ChatCompletion,
            method: .post,
            body: ChatRequest(model: usingModel, messages: messages)
        )

        let response = try await send(request: request)
        guard let answer = response.choices.first?.message.content else {
            throw GPTSwiftError.other(CustomError.couldNotParseAnswer)
        }

        return answer
    }

    /// Ask ChatGPT something by providing a chat request object, giving you full control over the request's configuration.
    /// - Parameter request: The request.
    /// - Returns: The response.
    public func ask(request: ChatRequest) async throws -> ChatResponse {
        let request = Request<ChatResponse>(
            path: API.v1ChatCompletion,
            method: .post,
            body: request
        )

        return try await send(request: request)
    }

    /// Sends the request, catches all errors and replaces them with a `GPTSwiftError`. If successful, it returns the response value.
    /// - Parameter request: The request to send.
    /// - Returns: The response object, already decoded.
    private func send<Response: Codable>(request: Request<Response>) async throws -> Response {
        do {
            return try await client.send(request).value
        } catch let error as APIError {
            switch error {
            case let .unacceptableStatusCode(int) where int == 401:
                throw GPTSwiftError.unauthorized
            default:
                throw GPTSwiftError.requestFailed
            }
        } catch {
            throw GPTSwiftError.requestFailed
        }
    }
}

public extension ChatGPT {
    enum CustomError: Error {
        case couldNotParseAnswer
    }
}
